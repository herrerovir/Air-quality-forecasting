{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2: Time Series Regression\n",
    "\n",
    "## Air Quality Forecasting\n",
    "\n",
    "**Author:** Virginia Herrero [Email](mailto:v.herrero@outlook.com) | [LinkedIn](https://www.linkedin.com/in/virginia-herrero-casero/) | [GitHub](https://github.com/herrerovir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "En este proyecto, se lleva a cabo un proceso de machine learning de principio a fin, con el objetivo de predecir la calidad del aire usando datos de series temporales. Este cuaderno detalla paso a paso todas las decisiones tomadas desde la limpieza de los datos hasta el desarrollo y evaluación del modelo.\n",
    "\n",
    "Elegí este conjunto de datos porque es relevante para mi formación como ingeniero químico especializada en control de calidad. Predecir la calidad del aire es una gran oportunidad para mostrar mis habilidades en ingeniería aplicada a la ciencia de datos, especialmente en el ámbito del control de calidad para diferentes industrias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "El conjunto de datos utilizado en este proyecto se obtuvo del UCI Machine Learning Repository [here](https://archive.ics.uci.edu/dataset/360/air+quality).\n",
    "\n",
    "La información proporcionada del conjunto de datos es la siguiente:\n",
    "\n",
    "- The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level, within an Italian city. \n",
    "\n",
    "- Data were recorded from March 2004 to February 2005 (one year) representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. \n",
    "\n",
    "- Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2) and were provided by a co-located reference certified analyzer.\n",
    "\n",
    "- Missing values are tagged with -200 value.\n",
    "\n",
    "Las variables de este conjunto de datos son las siguientes:\n",
    "\n",
    "- `Date`: (DD/MM/YYYY)\n",
    "\n",
    "- `Time`: (HH.MM.SS)\n",
    "\n",
    "- `CO(GT)`: True hourly averaged concentration CO in mg/m^3 (reference analyzer)\n",
    "\n",
    "- `PT08.S1(CO)`: (tin oxide) hourly averaged sensor response (nominally CO targeted)\n",
    "\n",
    "- `NMHC(GT)`: True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)\n",
    "\n",
    "- `C6H6(GT)`: True hourly averaged Benzene concentration  in microg/m^3 (reference analyzer)\n",
    "\n",
    "- `PT08.S2(NMHC)`: (titania) hourly averaged sensor response (nominally NMHC targeted)\n",
    "\n",
    "- `NOx(GT)`: True hourly averaged NOx concentration  in ppb (reference analyzer)\n",
    "\n",
    "- `PT08.S3(NOx)`: (tungsten oxide) hourly averaged sensor response (nominally NOx targeted)\n",
    "\n",
    "- `NO2(GT)`: True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)\n",
    "\n",
    "- `PT08.S4(NO2)`: (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)\n",
    "\n",
    "- `PT08.S5(O3)`: (indium oxide) hourly averaged sensor response (nominally O3 targeted)\n",
    "\n",
    "- `T`: Temperature in °C\n",
    "\n",
    "- `RH`: Relative Humidity (%)\n",
    "\n",
    "- `AH`: Absolute Humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "Carga el archivo CSV **AirQualityUCI** como un DataFrame de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Seasonal analysis\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Modeling and evaluation\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"AirQualityUCI.csv\", delimiter = \";\", decimal = \",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "Limpia y preprocesa el conjunto de datos antes de seguir con el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Elimina columnas innecesarias**\n",
    "\n",
    "Las columnas Unnamed: 15 y Unnamed: 16 están vacías, por lo tanto, se eliminan del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 15\", \"Unnamed: 16\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Renombra columnas**\n",
    "\n",
    "Algunas columnas se renombraron para proporcionar un contexto más claro y mejorar la comprensión para una audiencia no técnica del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {\"CO(GT)\" : \"CO_Concentration\",\n",
    "                          \"PT08.S1(CO)\" : \"CO_Sensor_Response\",\n",
    "                          \"NMHC(GT)\" : \"NMHC_Concentration\",\n",
    "                          \"C6H6(GT)\" : \"C6H6_Concentration\",\n",
    "                          \"PT08.S2(NMHC)\" : \"NMHC_Sensor_Response\",\n",
    "                          \"NOx(GT)\" : \"NOx_Concentration\",\n",
    "                          \"PT08.S3(NOx)\" : \"NOx_Sensor_Response\",\n",
    "                          \"NO2(GT)\" : \"NO2_Concentration\",\n",
    "                          \"PT08.S4(NO2)\" : \"NO2_Sensor_Response\",\n",
    "                          \"PT08.S5(O3)\" : \"O3_Sensor_Response\",\n",
    "                          \"T\" : \"Temperature\",\n",
    "                          \"RH\" : \"Relative_Humidity\",\n",
    "                          \"AH\" : \"Absolute_Humidity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataset with the renamed variables\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Valores nulos**\n",
    "\n",
    "Identifica y elimina cualquier valor nulo en el conjunto de datos cuando sea necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the total of null values in each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 114 valores nules en todas las columnas del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all the rows with missing values\n",
    "missing_rows = df[df.isna().any(axis = 1)]\n",
    "missing_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos tiene un total de 114 valores faltantes, lo cual es un porcentaje relativamente bajo, aproximadamente el 1.2% de todo el conjunto de datos. Dado este pequeño porcentaje, eliminaré todas las filas con valores nulos. Dado que se trata de una serie temporal, utilizar un método de imputación como el fill forward podría crear valores duplicados, ya que simplemente llevaría hacia adelante la última entrada no NaN disponible. Por lo tanto, eliminar estas filas es el mejor método para mantener la integridad de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La descripción del conjunto de datos indica que los valores faltantes están etiquetados con el valor -200. Por lo tanto, se buscarán todos los valores -200 y se reemplazarán por valores NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count -200 values in each column\n",
    "df.apply(lambda x : x == -200).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis del conteo de valores -200 muestra claramente que la característica **\"NMHC_Concentration\"** tiene una cantidad significativa de valores nulos. Por esta razón, esta columna se eliminará directamente del conjunto de datos. Posteriormente, todas las instancias de -200 se reemplazarán por valores NaN y se imputarán siguiendo el método de relleno hacia adelante, el cual es adecuado para las series temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the colum with too many missing values\n",
    "df.drop(columns = [\"NMHC_Concentration\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values with NaN\n",
    "df.replace(to_replace = -200, value = np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill missing values\n",
    "df.ffill(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check remaining missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Valores duplicados**\n",
    "\n",
    "Verifica si hay entradas duplicadas en el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset no tiene valores duplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Tipos de datos**\n",
    "\n",
    "Verifica que todas las columnas tengan los tipos de datos apropiados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas **\"Date\"** y **\"Time\"** están configuradas como tipos objeto, por lo que necesitan ser convertidas al tipo datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature with date and time\n",
    "df[\"Datetime\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time\"], format = \"%d/%m/%Y %H.%M.%S\")\n",
    "\n",
    "# Set the new feature as the index\n",
    "df = df.set_index(\"Datetime\")\n",
    "\n",
    "# Drop the unnecesary columns\n",
    "df = df.drop([\"Date\", \"Time\"], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again for missing values after transformation\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Outliers**\n",
    "\n",
    "Examina el resumen estadístico del conjunto de datos para identificar posibles valores atípicos. Esta visión general inicial ayudará a resaltar cualquier valor inusual que pueda requerir una exploración adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las estadísticas resumidas del conjunto de datos, es evidente que las siguientes variables muestran discrepancias importantes entre sus valores máximos y el cuartil superior, lo que indica la existencia de posibles valores atípicos.\n",
    "\n",
    "- CO_Concentration\n",
    "- C6H6_Concentration\n",
    "- NOx_Concentration\n",
    "\n",
    "Primero, se trazarán graficas de estas variables para identificar posibles valores atípicos. Luego, los valores atípicos se identificarán utilizando el método del rango intercuartílico (IQR). El análisis de la distribución de los datos revelará los valores que están fuera del rango típico, lo que permitirá seleccionar un enfoque adecuado para manejarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the CO concentration distribution using a histogram and boxplot\n",
    "CO_concentration_distribution = plt.figure()\n",
    "fig, ax = plt.subplots(1, 2, figsize = (11, 3))\n",
    "sns.histplot(df[\"CO_Concentration\"], ax = ax[0], color = \"#e7298a\")\n",
    "sns.boxplot(x = df[\"CO_Concentration\"], ax = ax[1], color = \"#e7298a\")\n",
    "ax[0].set_xlabel(\"Concentración de CO\")\n",
    "ax[1].set_xlabel(\"Concentración de CO\")\n",
    "plt.suptitle(\"Distribución de la concentración de CO\", size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the C6H6 concentration distribution using a histogram and boxplot\n",
    "C6H6_concentration_distribution = plt.figure()\n",
    "fig, ax = plt.subplots(1, 2, figsize = (11, 3))\n",
    "sns.histplot(df[\"C6H6_Concentration\"], ax = ax[0], color = \"#e7298a\")\n",
    "sns.boxplot(x = df[\"C6H6_Concentration\"], ax = ax[1], color = \"#e7298a\")\n",
    "ax[0].set_xlabel(\"Concentración de C$_6$H$_6$\")\n",
    "ax[1].set_xlabel(\"Concentración de C$_6$H$_6$\")\n",
    "plt.suptitle(\"Distribución de la concentración de C$_6$H$_6$\", size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the NOx concentration distribution using a histogram and boxplot\n",
    "NOx_concentration_distribution = plt.figure()\n",
    "fig, ax = plt.subplots(1, 2, figsize = (11, 3))\n",
    "sns.histplot(df[\"NOx_Concentration\"], ax = ax[0], color = \"#e7298a\")\n",
    "sns.boxplot(x = df[\"NOx_Concentration\"], ax = ax[1], color = \"#e7298a\")\n",
    "ax[0].set_xlabel(\"Concentración de NO$_x$\")\n",
    "ax[1].set_xlabel(\"Concentración de NO$_x$\")\n",
    "plt.suptitle(\"Distribución de la concentración de NO$_x$\", size = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encuentra los valores atípicos utilizando el método del rango intercuartílico (IQR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to find outliers using the IQR method\n",
    "\n",
    "def find_outliers_iqr(dataframe, column):\n",
    "    \"\"\"\n",
    "    Finds outliers in the specified column of a DataFrame using the IQR method\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : Pandas DataFrame\n",
    "        The DataFrame containing the data\n",
    "    \n",
    "    column : str\n",
    "        The name of the column (as a string) in which to find the outliers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        A DataFrame containing the outliers identified in the specified column\n",
    "   \"\"\"\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "    Q1 = dataframe[column].quantile(0.25)\n",
    "    Q3 = dataframe[column].quantile(0.75)\n",
    "    \n",
    "    # Calculate IQR\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Determine the bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers = dataframe[(dataframe[column] < lower_bound) | (dataframe[column] > upper_bound)]\n",
    "    print(f\"The number of outliers in the column {column} is {outliers.shape[0]}\")\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers in the dataset\n",
    "for i in df.columns:\n",
    "    find_outliers_iqr(df, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del análisis estadístico de los valores atípicos, se puede concluir que hay una gran cantidad de valores fuera de rango. Teniendo en cuenta la naturaleza de las características, los valores atípicos podrían estar presentes debido a picos de contaminación en el aire. Por lo tanto, estos datos podrían ser relevantes. Sin embargo, la presencia de valores atípicos puede afectar el rendimiento del modelo que se utilizarán posteriormente para predecir los 100 ciclos. Por estas razones, he decidido limitar los valores atípicos para conservar todos los datos, pero reducir el posible impacto negativo que puedan tener en el modelo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers(dataframe, column):\n",
    "    \"\"\"\n",
    "    Cap outliers in a specified column of the DataFrame using the IQR method\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe : Pandas DataFrame\n",
    "        The DataFrame containing the data\n",
    "    \n",
    "    column : str\n",
    "        The name of the column to cap outliers\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        A DataFrame with outliers capped\n",
    "    \"\"\"\n",
    "    if column not in dataframe.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in DataFrame.\")\n",
    "    \n",
    "    # Calculate Q1 and Q3\n",
    "    Q1 = dataframe[column].quantile(0.25)\n",
    "    Q3 = dataframe[column].quantile(0.75)\n",
    "\n",
    "    # Calculate IQR\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Cap the outliers\n",
    "    dataframe[column] = dataframe[column].clip(lower = lower_bound, upper = upper_bound)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap outliers\n",
    "for i in df.columns:\n",
    "    cap_outliers(df, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribución de las características después de limitar los outliers es la siguiente: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize = (20, 10), color = \"#e7298a\")\n",
    "plt.suptitle(\"Distribución de las características\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **El conjunto de datos limpio:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = df.copy()\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "air_quality.to_csv(\"Air-quality-cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonality\n",
    "\n",
    "El requerimiento de este ejercicio es que la serie temporal sea **no-estacional**. La estacionalidad se refiere a las fluctuaciones periódicas de un conjunto de datos. Estos intervalos regulares se producen debido a factores estacionales. Para determinar si la serie temporal es no-estacional, primero hay que comprobar si la serie es **estacionaria**. Para ello se emplea la prueba estadística de Dickey-Fuller la cual consiste en detectar la presencia de una raíz unitaria la cual indica no estacionariedad. Si el resultado de la prueba es significativo, sugiere que la serie es estacionaria, y por tanto, no presenta estacionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_seasonality(series):\n",
    "    \"\"\"\n",
    "    Perform the Dickey-Fuller test to check for seasonality and print the results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : Pandas Series\n",
    "        The time series data to test for seasonality.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    result = adfuller(series)\n",
    "    adf_statistic = result[0]\n",
    "    p_value = result[1]\n",
    "    critical_values = result[4]\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Dickey-Fuller Test Results:\\n\")\n",
    "    print(f\"ADF Statistic: {adf_statistic}\")\n",
    "    print(f\"p-value: {p_value}\")\n",
    "\n",
    "    for key, value in critical_values.items():\n",
    "        print(f\"Critical Value {key}: {value}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    interpretation = (\"The time series is stationary, indicating the absence of seasonality.\"\n",
    "                      if p_value < 0.05 else\n",
    "                      \"The time series is non-stationary, suggesting it may  seasonality.\")\n",
    "    print(f\"\\nInterpretation: {interpretation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check seasonality on target variable\n",
    "adf_result = check_seasonality(air_quality[\"NO2_Concentration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de la prueba de Dickey-Fuller indican que la serie temporal es **no estacional**.\n",
    "\n",
    "- **Estacionariedad**: La estadística ADF es menor que los valores críticos y el valor p es muy bajo. Esto significa que la serie es estacionaria, lo que sugiere que no tiene tendencias ni fluctuaciones que cambien con el tiempo.\n",
    "\n",
    "- **No Estacionalidad**: La falta de estacionalidad significa que no hay patrones repetidos en intervalos regulares. Esto implica que la serie no muestra variaciones predecibles según la época del año o del mes.\n",
    "\n",
    "Por estas razones, podemos afirmar que la serie temporal es no estacional y estacionaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the NO2 concentration over time\n",
    "plt.figure(figsize = (11, 4))\n",
    "plt.plot(air_quality[\"NO2_Concentration\"], color = \"#e7298a\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Concentración de NO$_2$\")\n",
    "plt.title(\"Concentración de NO$_2$ a lo largo del tiempo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform seasonal decomposition of the NO2 concentration data\n",
    "result = seasonal_decompose(air_quality[\"NO2_Concentration\"], model = \"additive\", period = 365)\n",
    "\n",
    "# Plot the decomposition results\n",
    "plt.figure(figsize = (14, 10))\n",
    "result.plot()\n",
    "plt.suptitle(\"Descomposición Estacional de la Concentración de NO$_2$\")\n",
    "\n",
    "# Change the color of the lines in the plot and set axis labels\n",
    "for ax in plt.gcf().axes:\n",
    "    for line in ax.lines:\n",
    "        line.set_color(\"#e7298a\")\n",
    "    ax.set_xlabel(\"Tiempo\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de la descomposición estacional muestran los componentes de la serie temporal para comprender mejor la dinámica de la concentración de NO<sub>2</sub> a lo largo del tiempo:\n",
    "\n",
    "1. **Observado**: datos originales de las concentraciones de NO<sub>2</sub>\n",
    "2. **Tendencia**: tendencia general a largo plazo de las concentraciones de NO<sub>2</sub>\n",
    "3. **Estacional**: patrones repetitivos en intervalos regulares de las concentraciones de NO<sub>2</sub>\n",
    "4. **Residual**: fluctuaciones aleatorias no explicadas por la tendencia o estacionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Target Variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable objetivo de este proyecto es la concentración de NO<sub>2</sub>. He elegido esta variable por las siguientes razones:\n",
    "\n",
    "- De entre todos los contaminantes del dataset, NO<sub>2</sub> es uno de los más perjudiciales para la salud.\n",
    "- Los efectos de NO<sub>2</sub> sobre la salud están bien documentados.\n",
    "- La regulación establece valores máximos y claros para este gas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Concentraciones mensuales de NO<sub>2</sub>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample and plot the monthly mean of NO2 concentration levels\n",
    "monthly_no2 = air_quality[\"NO2_Concentration\"].resample(\"ME\").mean()\n",
    "\n",
    "ax = monthly_no2.plot(kind = \"bar\", figsize = (11, 4), color = \"#e7298a\")\n",
    "plt.xlabel(\"Mes\")\n",
    "plt.ylabel(\"Concentración promedio de NO$_2$\")\n",
    "ax.set_xticks(range(len(monthly_no2)))\n",
    "ax.set_xticklabels(monthly_no2.index.strftime(\"%B, %Y\"))\n",
    "plt.title(\"Concentraciones promedio mensuales de NO$_2$\");       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las concentraciones de NO<sub>2</sub> entre marzo de 2004 y abril de 2005 muestran que las concentraciones de este gas aumentan durante los meses de invierno y durante el verano decrecen hasta llegar al mínimo en agosto. Esto probablemente es debido al uso de calefacciónes en las casas y comercios, el transporte y mayor uso de electricidad. variaron. También se observa que existe una tendencia general al alza en los niveles de NO<sub>2</sub>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Concentraciones de NO<sub>2</sub> por hora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data to get hourly mean values\n",
    "hourly_no2 = air_quality[\"NO2_Concentration\"].resample(\"h\").mean()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(x=hourly_no2.index.hour, y=hourly_no2.values, errorbar = None, color = \"#e7298a\")\n",
    "plt.xlabel(\"Hora del día\")\n",
    "plt.ylabel(\"Concentración promedio de NO$_2$\")\n",
    "plt.title(\"Concentración promedio por hora de NO$_2$\")\n",
    "plt.xticks(range(24), [f\"{h}:00\" for h in range(24)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los niveles de NO<sub>2</sub> fluctúan durante el día de manera significativa, oscilando entre 92.0 y 190.0 ppb. Las concentraciones comienzan en 113.0 ppb a medianoche y aumentan a lo largo de la tarde, alcanzando un pico de 122.0 ppb alrededor de las 21:00. Los niveles son más bajos durante la noche, probablemente debido a un menor uso del transporte, electricidad, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns and resample the data by month, calculating the mean\n",
    "monthly_mean = air_quality.drop([\"Temperature\", \"Relative_Humidity\", \"Absolute_Humidity\"], axis=1).resample(\"ME\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot monthy average values of all the gases\n",
    "colors = [\"black\", \"blue\", \"deepskyblue\", \"lightseagreen\", \"limegreen\", \"gold\", \"darkorange\", \"chocolate\", \"deeppink\"]\n",
    "\n",
    "monthly_mean.plot(figsize=(15, 8), color=colors)\n",
    "plt.xlabel(\"Mes\")\n",
    "plt.ylabel(\"Concentración promedio de gases tóxicos\")\n",
    "plt.title(\"Concentración mensual promedio de gases tóxicos\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los gráfica que representa las concentraciones mensuales promedios de los gases en el aire, muestra que éstas fluctuan significativamente a lo largo del tiempo. La única que se mantiene bastante estable es la concentración de CO se mantiene bastante estable. Por otro lado, el benceno muestra más variabilidad. Las concentraciones de NO<sub>x</sub> y NO<sub>2</sub> son mucho más altas durante el otoño e invierno, lo que probablemente sea debido al aumento en el uso de calefacción y tráfico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Matriz de Correlación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = air_quality.corr(numeric_only = True)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_heatmap_graph = plt.figure(figsize = (11, 4))\n",
    "sns.heatmap(correlations, linewidths = 0.5, annot = True, cmap = \"PuRd\")\n",
    "plt.title(\"Correlation Heatmap\", size = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de correlación muestra las relaciones entre las diferentes variables, cuánto más fuerte es el color, más relación hay entre las variables. Las relaciones más importantes entre los parámetros de calidad del aire son los siguientes:\n",
    "\n",
    "1. **Correlaciones Fuertes**:\n",
    "   - La concentración de CO se relaciona estrechamente con su sensor y con la concentración de C6H<sub>6</sub>.\n",
    "   - Las respuestas de los sensores de C6H<sub>6</sub> y NMHC perfectamente correlacionadas.\n",
    "\n",
    "2. **Compuestos de Nitrógeno**:\n",
    "   - NOx y NO<sub>2</sub> tienen una fuerte correlación positiva, lo que significa que cuando uno aumenta, el otro también aumenta.\n",
    "   - La respuesta del sensor de NOx se correlaciona negativamente con su concentración. Esto puede indicar que el sensor no funciona correctamente.\n",
    "\n",
    "3. **Temperatura y Humedad**:\n",
    "   - La temperatura tiene una leve correlación positiva con el sensor de NO<sub>2</sub> y negativa con CO.\n",
    "   - La humedad absoluta se correlaciona más fuerte con la temperatura y el sensor de NO<sub>2</sub>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Eliminación de Columnas**\n",
    "\n",
    "Se eliminaron las columnas **NMHC_Sensor_Response** y **NOx_Sensor_Response** debido a:\n",
    "\n",
    "- **NOx_Sensor_Response**: Fuerte correlación negativa con varias características y redundancia con NOx_Concentration.\n",
    "  \n",
    "- **NMHC**: Su alta correlación con C6H<sub>6</sub> sugiere que los niveles de ambos están midiendo compuestos similares y supone redundancia de datos.\n",
    "\n",
    "Eliminando ambas características evitamos posibles problemas de multicolinealidad en el modelo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = air_quality.drop([\"NMHC_Sensor_Response\", \"C6H6_Concentration\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to prepare the data for LSTM model\n",
    "def create_dataset(data, time_step = 1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data) - time_step):\n",
    "        X.append(data[i:(i + time_step)])\n",
    "        Y.append(data[i + time_step])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Normalize the data\n",
    "data = air_quality[\"NO2_Concentration\"].values\n",
    "data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "# Set the time steps to create sequences for the model\n",
    "time_step = 24\n",
    "\n",
    "# Create the dataset to feed to the LSTM model\n",
    "X, y = create_dataset(data, time_step)\n",
    "\n",
    "# Reshape the data to be compatible with the LSTM model\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor = \"val_loss\", patience = 5)\n",
    "history = model.fit(X_train, y_train, epochs = 50, batch_size = 64, validation_split = 0.2, callbacks = [early_stopping])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_pred = y_pred.reshape(-1, 1)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (R²): {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo, con dos capas de LSTM y una completamente conectada es una excelente opción para resolver este problema por las siguientes razones:\n",
    "\n",
    "- **Generalización**: la pérdida de validación se mantiene cercana a la pérdida de entrenamiento, lo que indica una buena capacidad de generalización a datos no vistos.\n",
    "- **Métricas de Error**: las métricas de evaluación del modelo reflejan predicciones confiables.\n",
    "- **Poder Predictivo**: el alto valor de R² demuestra que el modelo captura eficazmente las tendencias en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"LSTM-model-air-quality.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pérdida de entrenamieto y validación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss curves\n",
    "plt.figure(figsize = (11, 4))\n",
    "plt.plot(history.history[\"loss\"], label = \"Pérdida de entrenamiento\", color = \"#e7298a\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"Pérdida de validación\", color = \"deepskyblue\")\n",
    "plt.title(\"Pérdida del modelo LSTM a lo largo de las épocas\")\n",
    "plt.ylabel(\"Pérdida\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicciones vs Valores Reales y valor R2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular r2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Plot predictions vs actual values\n",
    "plt.figure(figsize =  (11, 4))\n",
    "plt.plot(y_test, label=\"Concentración de NO$_2$ Real\", color = \"#e7298a\")\n",
    "plt.plot(y_pred, label=\"Concentración de NO$_2$ Predicha\", color = \"deepskyblue\")\n",
    "plt.title(f\"Predicciones vs Valores Reales (R² = {r2:.2f})\")\n",
    "plt.ylabel(\"Concentración de NO$_2$\")\n",
    "plt.xlabel(\"Pasos de Tiempo\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gráfica de residuos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residual\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(11, 4))\n",
    "plt.scatter(range(len(residuals)), residuals, color = \"#e7298a\")\n",
    "plt.axhline(y = 0, color = \"deepskyblue\", linestyle = \"--\")\n",
    "plt.title(\"Residuos\")\n",
    "plt.ylabel(\"Residuos\")\n",
    "plt.xlabel(\"Índice\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograma de residuos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals histogram\n",
    "plt.figure(figsize = (11, 4))\n",
    "plt.hist(residuals, bins = 30, alpha = 0.7, color = \"#e7298a\")\n",
    "plt.title(\"Histograma de residuos\")\n",
    "plt.xlabel(\"Residuos\")\n",
    "plt.ylabel(\"Frequencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro de los requisitos de este ejercico es predecir 100 ciclos en el futuro sin utilizar las variables regresoras. Para ello se prepara la última entrada del dataset para que sea compatible con el modelo LSTM. Luego, se itera 100 veces para predecir los siguientes valores, agregando cada nuevo valor pronosticado a una lista que los guarda todos. Finalmente, se imprimen en la consola las predicciones para los próximos 100 pasos de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of time steps to forecast\n",
    "num_forecasts = 100\n",
    "\n",
    "# Reshape input to fit LSTM\n",
    "last_input = data[-time_step:].reshape(1, time_step, 1)\n",
    "\n",
    "# List to store the forecasted values\n",
    "forecasted_values = []\n",
    "\n",
    "# Iterate to predict the next value\n",
    "for _ in range(num_forecasts):\n",
    "    next_value = model.predict(last_input) \n",
    "    forecasted_values.append(next_value[0, 0])\n",
    "    last_input = np.concatenate((last_input[:, 1:, :], next_value.reshape(1, 1, 1)), axis=1)\n",
    "\n",
    "# Convert the forecasted values to a numpy array\n",
    "forecasted_values = np.array(forecasted_values)\n",
    "\n",
    "# Print the forecasted values\n",
    "print(f\"Forecasted values for the next 100 time steps:\\n {forecasted_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este ejercicio fue crear un modelo de machine learning para predecir la calidad del aire en el futuro. El primer paso y uno de los más importantes es la limpieza de los datos. Este es una etapa esencial en el análisis de datos para asegurar que la información sea íntegra y confiable. Además, Se verificó que no hubiera estacionalidad en los datos, tal como se mencionaba en el planteamiento del problema. Antes del modelado se llevó a cabo una exploración de las variables para descubrir información relevante, tendencias y relaciones entre las variables. \n",
    "\n",
    "El modelo elegido para este proyecto fue una red neuronal recurrente, en concreto LSTM (Long Short-Term Memory). Lo interesante de la LSTM es que está hecha para aprender de datos en secuencia, lo que la hace perfecta para predecir la calidad del aire\n",
    "\n",
    "Al final, se logró construir un modelo sólido que mostró métricas de evaluación muy buenas y una alta puntuación R², lo que indica un rendimiento efectivo. Por último, se realizaron predicciones para los próximos 100 ciclos sin utilizar variables de regresión, tal como se había solicitado en el ejercicio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
